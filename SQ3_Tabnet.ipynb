{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a91b1af-4f87-4309-93d6-cbf5d36617e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runned!\n",
      "['PCA', 'SMOTE', 'SimpleImputer', 'StandardScaler', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'create_pca_table', 'np', 'pca_on_train_and_transform_full_data', 'pd', 'plt', 'preprocess_and_apply_smote1', 'remove_outliers_iqr', 'scale_columns1', 'scale_columns2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-92ac18f58d88>:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y_train = y_train.replace({'1': 1, '4': 0})\n",
      "<ipython-input-1-92ac18f58d88>:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y_val = y_val.replace({'1': 1, '4': 0})\n",
      "<ipython-input-1-92ac18f58d88>:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y_test = y_test.replace({'1': 1, '4': 0})\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#https://www.kaggle.com/code/enigmak/tabnet-deep-neural-network-for-tabular-data\n",
    "\n",
    "#from base1 import *\n",
    "from base2 import *\n",
    "\n",
    "X_train_1 = pd.read_csv('csv/X_train_eu.csv', index_col='Unnamed: 0')\n",
    "y_train = pd.read_csv('csv/y_train_eu.csv', index_col='Unnamed: 0')\n",
    "X_val_1 = pd.read_csv('csv/X_val_eu.csv', index_col='Unnamed: 0')\n",
    "y_val = pd.read_csv('csv/y_val_eu.csv', index_col='Unnamed: 0')\n",
    "X_test_1 = pd.read_csv('csv/X_test_eu.csv', index_col='Unnamed: 0')\n",
    "y_test = pd.read_csv('csv/y_test_eu.csv', index_col='Unnamed: 0')\n",
    "\n",
    "y_train = (y_train['auop']).astype(str)\n",
    "y_val = (y_val['auop']).astype(str)\n",
    "y_test = (y_test['auop']).astype(str)\n",
    "\n",
    "y_train = y_train.replace({'1': 1, '4': 0})\n",
    "y_val = y_val.replace({'1': 1, '4': 0})\n",
    "y_test = y_test.replace({'1': 1, '4': 0})\n",
    "\n",
    "X_train = X_train_1\n",
    "X_val = X_val_1\n",
    "X_test = X_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcdbc66-49b0-42d2-bf82-bb3c4cb80c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns dropped: ['X20', 'X119']\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-f194cd05e0f5>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_val['X141'].fillna(0, inplace=True)\n",
      "<ipython-input-2-f194cd05e0f5>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test['X141'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Calculate frequency encoding on the training set\n",
    "frequency_encoding = X_train['X140'].value_counts(normalize=True)\n",
    "# Map the frequencies to the sector column in each dataset\n",
    "X_train['X141'] = X_train['X140'].map(frequency_encoding)\n",
    "X_val['X141'] = X_val['X140'].map(frequency_encoding)\n",
    "X_test['X141'] = X_test['X140'].map(frequency_encoding)\n",
    "# Fill any missing values that might arise if a category in val/test wasn't in train\n",
    "X_val['X141'].fillna(0, inplace=True)\n",
    "X_test['X141'].fillna(0, inplace=True)\n",
    "\n",
    "X_train = X_train.drop(columns=['X140'])\n",
    "X_val = X_val.drop(columns=['X140'])\n",
    "X_test = X_test.drop(columns=['X140'])\n",
    "\n",
    "# Deal with missing values in the features \n",
    "missing_threshold = 0.8\n",
    "missing_train = X_train.isnull().mean()\n",
    "cols_to_drop = missing_train[missing_train > missing_threshold].index\n",
    "# Drop the identified columns from both the training and test sets\n",
    "X_train = X_train.drop(cols_to_drop, axis=1)\n",
    "X_val = X_val.drop(cols_to_drop, axis=1)\n",
    "X_test = X_test.drop(cols_to_drop, axis=1)\n",
    "print(f\"Columns dropped: {list(cols_to_drop)}\")\n",
    "print(len(cols_to_drop))\n",
    "\n",
    "col_names = X_train.columns.to_list()\n",
    "col_names.remove(\"X23\")\n",
    "col_names.remove(\"X141\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55cf106-4023-4767-baf3-273e9f9ccd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'inf' and '-inf' with NaN\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_val.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Initialize SimpleImputer with the 'mean' strategy\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "# Fit the imputer on the training data and transform it\n",
    "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "# Apply the same imputer to the validation and test sets (without refitting)\n",
    "X_val = pd.DataFrame(imputer.transform(X_val), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8802b0df-219c-4fd6-817f-6ba149b2d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, f1_score, precision_recall_curve, auc\n",
    "\n",
    "# Convert DataFrames to NumPy arrays\n",
    "X_train_np = X_train.values\n",
    "X_val_np = X_val.values\n",
    "X_test_np = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c6dfe-6481-4c98-9561-8a2e5bbb66d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import average_precision_score\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40d8ea-7e6b-4afc-93bd-8234c9fc2032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    hyperparams = {\n",
    "        'n_a_d': trial.suggest_categorical('n_a_d', [8, 16, 24, 32, 64, 128, 256]),\n",
    "        'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n",
    "        'gamma': trial.suggest_categorical('gamma', [0.01, 0.05, 0.1, 0.5, 0.8, 1.0, 1.2, 1.5, 2.0]),\n",
    "        'lambda': trial.suggest_categorical('lambda', [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0]),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [1024, 2048, 4096, 8192, 16384, 32768]),\n",
    "        'virtual_batch_size': trial.suggest_categorical('virtual_batch_size', [128, 256, 512, 1024, 2028, 4096]),\n",
    "        'lr': trial.suggest_categorical('lr', [0.005, 0.01, 0.02, 0.025, 0.03, 0.04, 0.05]),\n",
    "        'gamma_decay': trial.suggest_categorical('gamma_decay', [0.4, 0.8, 0.9, 0.95]),\n",
    "        'mask_type': trial.suggest_categorical('mask_type', ['entmax', 'sparsemax']),\n",
    "        'batch_momentum': trial.suggest_categorical('batch_momentum', [0.6, 0.7, 0.8, 0.9, 0.95, 0.98]),\n",
    "    }\n",
    "    MAX_EPOCHS = 35\n",
    "    PATIENCE = 5\n",
    "    model = TabNetClassifier(\n",
    "        n_d=hyperparams['n_a_d'],\n",
    "        n_a=hyperparams['n_a_d'],\n",
    "        gamma=hyperparams['gamma'],\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params={'lr':hyperparams['lr']},\n",
    "        scheduler_params={\"step_size\":hyperparams['n_steps'],\n",
    "                          \"gamma\":hyperparams['gamma_decay']},\n",
    "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "        mask_type=hyperparams['mask_type'],\n",
    "        lambda_sparse=hyperparams['lambda'],\n",
    "        momentum=hyperparams['batch_momentum'],\n",
    "        verbose = 0\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train=X_train_np, y_train=y_train,\n",
    "        eval_set=[(X_train_np, y_train), (X_val_np, y_val)],\n",
    "        eval_name=['train', 'val'],\n",
    "        max_epochs=MAX_EPOCHS, \n",
    "        patience=PATIENCE,\n",
    "        batch_size=hyperparams['batch_size'],\n",
    "        virtual_batch_size=hyperparams['virtual_batch_size'],\n",
    "        num_workers=0,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    val_preds = model.predict(X_val_np)\n",
    "    \n",
    "    del model\n",
    "\n",
    "    return average_precision_score(y_val,val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63276ffe-1961-410e-90d9-fe2e6f9640da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/optuna/_experimental.py:30: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2024-11-18 10:23:08,979] A new study created in memory with name: no-name-0ff3b853-87a1-4ac9-93ca-bb569da8eb3a\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize',\n",
    "                            sampler=optuna.samplers.TPESampler(multivariate=True, seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e653967-1b3c-4fca-858a-4d1cf5e2d981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 11 and best_val_auc = 0.72921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:23:26,670] Trial 0 finished with value: 0.7669368913646283 and parameters: {'n_a_d': 16, 'n_steps': 9, 'gamma': 0.5, 'lambda': 0.0001, 'batch_size': 1024, 'virtual_batch_size': 1024, 'lr': 0.05, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.6}. Best is trial 0 with value: 0.7669368913646283.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 9 with best_epoch = 4 and best_val_auc = 0.57302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:24:15,044] Trial 1 finished with value: 0.7649807197313618 and parameters: {'n_a_d': 256, 'n_steps': 5, 'gamma': 1.0, 'lambda': 0, 'batch_size': 32768, 'virtual_batch_size': 256, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.7}. Best is trial 0 with value: 0.7669368913646283.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 30 and best_val_auc = 0.70392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:24:31,704] Trial 2 finished with value: 0.7729262034716449 and parameters: {'n_a_d': 8, 'n_steps': 7, 'gamma': 0.05, 'lambda': 1e-06, 'batch_size': 4096, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.9}. Best is trial 2 with value: 0.7729262034716449.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 14 and best_val_auc = 0.62351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:24:45,516] Trial 3 finished with value: 0.7626172149286112 and parameters: {'n_a_d': 24, 'n_steps': 4, 'gamma': 0.1, 'lambda': 0, 'batch_size': 16384, 'virtual_batch_size': 2028, 'lr': 0.05, 'gamma_decay': 0.9, 'mask_type': 'sparsemax', 'batch_momentum': 0.7}. Best is trial 2 with value: 0.7729262034716449.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 17 and best_val_auc = 0.62743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:25:07,309] Trial 4 finished with value: 0.7611354335654696 and parameters: {'n_a_d': 24, 'n_steps': 7, 'gamma': 2.0, 'lambda': 1e-07, 'batch_size': 1024, 'virtual_batch_size': 256, 'lr': 0.005, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 2 with value: 0.7729262034716449.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 21 and best_val_auc = 0.72958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:25:24,366] Trial 5 finished with value: 0.769199098519293 and parameters: {'n_a_d': 8, 'n_steps': 7, 'gamma': 0.8, 'lambda': 0, 'batch_size': 1024, 'virtual_batch_size': 512, 'lr': 0.03, 'gamma_decay': 0.4, 'mask_type': 'entmax', 'batch_momentum': 0.7}. Best is trial 2 with value: 0.7729262034716449.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 8 with best_epoch = 3 and best_val_auc = 0.55244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:25:30,077] Trial 6 finished with value: 0.7652848624885162 and parameters: {'n_a_d': 8, 'n_steps': 6, 'gamma': 1.5, 'lambda': 1e-06, 'batch_size': 32768, 'virtual_batch_size': 128, 'lr': 0.025, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 2 with value: 0.7729262034716449.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 11 and best_val_auc = 0.58265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:25:42,282] Trial 7 finished with value: 0.7638376837912363 and parameters: {'n_a_d': 32, 'n_steps': 9, 'gamma': 2.0, 'lambda': 0.0001, 'batch_size': 8192, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 2 with value: 0.7729262034716449.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 30 and best_val_auc = 0.72147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:26:39,944] Trial 8 finished with value: 0.7672172050946546 and parameters: {'n_a_d': 128, 'n_steps': 6, 'gamma': 2.0, 'lambda': 1e-07, 'batch_size': 4096, 'virtual_batch_size': 512, 'lr': 0.025, 'gamma_decay': 0.9, 'mask_type': 'entmax', 'batch_momentum': 0.7}. Best is trial 2 with value: 0.7729262034716449.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 11 and best_val_auc = 0.64001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:26:55,946] Trial 9 finished with value: 0.7641425239872479 and parameters: {'n_a_d': 64, 'n_steps': 6, 'gamma': 1.2, 'lambda': 0.01, 'batch_size': 4096, 'virtual_batch_size': 4096, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.6}. Best is trial 2 with value: 0.7729262034716449.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 22 and best_val_auc = 0.70354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:27:42,490] Trial 10 finished with value: 0.7701778130669558 and parameters: {'n_a_d': 128, 'n_steps': 4, 'gamma': 0.05, 'lambda': 1e-07, 'batch_size': 4096, 'virtual_batch_size': 1024, 'lr': 0.05, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.9}. Best is trial 2 with value: 0.7729262034716449.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 19 and best_val_auc = 0.74331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:28:02,343] Trial 11 finished with value: 0.7747381277427644 and parameters: {'n_a_d': 32, 'n_steps': 9, 'gamma': 0.1, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.9}. Best is trial 11 with value: 0.7747381277427644.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 19 and best_val_auc = 0.74378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:28:22,042] Trial 12 finished with value: 0.7800486634596242 and parameters: {'n_a_d': 32, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.9}. Best is trial 12 with value: 0.7800486634596242.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 21 and best_val_auc = 0.76299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:29:06,046] Trial 13 finished with value: 0.7814819980725985 and parameters: {'n_a_d': 128, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 13 with value: 0.7814819980725985.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 24 and best_val_auc = 0.7137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:29:58,617] Trial 14 finished with value: 0.7662882129186822 and parameters: {'n_a_d': 128, 'n_steps': 5, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 128, 'lr': 0.005, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.6}. Best is trial 13 with value: 0.7814819980725985.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 22 and best_val_auc = 0.74387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:30:14,278] Trial 15 finished with value: 0.776500963522815 and parameters: {'n_a_d': 8, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 13 with value: 0.7814819980725985.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 23 and best_val_auc = 0.68447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:31:02,813] Trial 16 finished with value: 0.7664867785523879 and parameters: {'n_a_d': 128, 'n_steps': 9, 'gamma': 2.0, 'lambda': 0, 'batch_size': 4096, 'virtual_batch_size': 1024, 'lr': 0.03, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 13 with value: 0.7814819980725985.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 7 and best_val_auc = 0.59263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:31:32,540] Trial 17 finished with value: 0.7668803466867936 and parameters: {'n_a_d': 128, 'n_steps': 9, 'gamma': 1.2, 'lambda': 0.001, 'batch_size': 16384, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.9, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 13 with value: 0.7814819980725985.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 18 and best_val_auc = 0.74238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:31:49,725] Trial 18 finished with value: 0.7938735833360016 and parameters: {'n_a_d': 32, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 18 with value: 0.7938735833360016.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 34 and best_val_auc = 0.75934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:32:47,977] Trial 19 finished with value: 0.7720868881244292 and parameters: {'n_a_d': 128, 'n_steps': 5, 'gamma': 2.0, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 18 with value: 0.7938735833360016.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 31 and best_val_auc = 0.70588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:33:14,204] Trial 20 finished with value: 0.7714890818816345 and parameters: {'n_a_d': 32, 'n_steps': 7, 'gamma': 0.05, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.005, 'gamma_decay': 0.9, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 18 with value: 0.7938735833360016.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 22 and best_val_auc = 0.7167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:33:33,667] Trial 21 finished with value: 0.7648578083978023 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 1.2, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 512, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 18 with value: 0.7938735833360016.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 29 and best_val_auc = 0.76756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:34:28,988] Trial 22 finished with value: 0.7879053720999016 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 18 with value: 0.7938735833360016.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 5 with best_epoch = 0 and best_val_auc = 0.56732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:34:40,240] Trial 23 finished with value: 0.7619716103028 and parameters: {'n_a_d': 128, 'n_steps': 6, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 8192, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 18 with value: 0.7938735833360016.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 30 and best_val_auc = 0.74495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:35:33,902] Trial 24 finished with value: 0.7947849889761689 and parameters: {'n_a_d': 128, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 24 with value: 0.7947849889761689.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 8 with best_epoch = 3 and best_val_auc = 0.5376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:35:39,434] Trial 25 finished with value: 0.7747866095476428 and parameters: {'n_a_d': 16, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.1, 'batch_size': 16384, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 24 with value: 0.7947849889761689.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 7 with best_epoch = 2 and best_val_auc = 0.54646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:35:45,180] Trial 26 finished with value: 0.7629052236236492 and parameters: {'n_a_d': 24, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0, 'batch_size': 16384, 'virtual_batch_size': 512, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 24 with value: 0.7947849889761689.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 7 and best_val_auc = 0.58916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:36:12,269] Trial 27 finished with value: 0.7631525315452349 and parameters: {'n_a_d': 128, 'n_steps': 9, 'gamma': 1.0, 'lambda': 0.001, 'batch_size': 32768, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 24 with value: 0.7947849889761689.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 30 and best_val_auc = 0.76337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:38:15,519] Trial 28 finished with value: 0.7836913294215837 and parameters: {'n_a_d': 256, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 1024, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.4, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 24 with value: 0.7947849889761689.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 18 and best_val_auc = 0.64527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:38:58,892] Trial 29 finished with value: 0.7669654801300879 and parameters: {'n_a_d': 128, 'n_steps': 10, 'gamma': 2.0, 'lambda': 0.001, 'batch_size': 8192, 'virtual_batch_size': 4096, 'lr': 0.01, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 24 with value: 0.7947849889761689.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 25 and best_val_auc = 0.75453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:40:49,511] Trial 30 finished with value: 0.7918253172037067 and parameters: {'n_a_d': 256, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 24 with value: 0.7947849889761689.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 28 and best_val_auc = 0.76651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:42:49,110] Trial 31 finished with value: 0.7850895971067862 and parameters: {'n_a_d': 256, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 24 with value: 0.7947849889761689.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 22 and best_val_auc = 0.71372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:43:10,742] Trial 32 finished with value: 0.7647353006665023 and parameters: {'n_a_d': 32, 'n_steps': 9, 'gamma': 1.2, 'lambda': 0, 'batch_size': 4096, 'virtual_batch_size': 2028, 'lr': 0.03, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 24 with value: 0.7947849889761689.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 14 and best_val_auc = 0.67778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:44:35,116] Trial 33 finished with value: 0.7694750636526806 and parameters: {'n_a_d': 256, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 8192, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 24 with value: 0.7947849889761689.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 28 and best_val_auc = 0.74456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:46:34,542] Trial 34 finished with value: 0.7846860154572142 and parameters: {'n_a_d': 256, 'n_steps': 8, 'gamma': 0.05, 'lambda': 1e-05, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.98}. Best is trial 24 with value: 0.7947849889761689.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 28 and best_val_auc = 0.75891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:47:07,416] Trial 35 finished with value: 0.7985649154799528 and parameters: {'n_a_d': 64, 'n_steps': 8, 'gamma': 0.01, 'lambda': 1e-05, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 5 and best_val_auc = 0.58039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:47:18,688] Trial 36 finished with value: 0.7626499648950154 and parameters: {'n_a_d': 64, 'n_steps': 7, 'gamma': 1.0, 'lambda': 1e-05, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.05, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.6}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 11 and best_val_auc = 0.7376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:47:36,100] Trial 37 finished with value: 0.7805590618208696 and parameters: {'n_a_d': 64, 'n_steps': 7, 'gamma': 0.01, 'lambda': 1e-05, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 7 with best_epoch = 2 and best_val_auc = 0.52984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:47:41,445] Trial 38 finished with value: 0.7678553925695514 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 32768, 'virtual_batch_size': 2028, 'lr': 0.01, 'gamma_decay': 0.9, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 9 with best_epoch = 4 and best_val_auc = 0.61806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:47:51,057] Trial 39 finished with value: 0.7668568387286908 and parameters: {'n_a_d': 64, 'n_steps': 8, 'gamma': 0.01, 'lambda': 1e-05, 'batch_size': 8192, 'virtual_batch_size': 2028, 'lr': 0.025, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 12 and best_val_auc = 0.6015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:48:02,877] Trial 40 finished with value: 0.7675162070642054 and parameters: {'n_a_d': 32, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.1, 'batch_size': 32768, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 15 and best_val_auc = 0.70873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:48:17,694] Trial 41 finished with value: 0.7696998853331383 and parameters: {'n_a_d': 16, 'n_steps': 6, 'gamma': 0.01, 'lambda': 1e-07, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.9, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 20 and best_val_auc = 0.75592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:48:47,103] Trial 42 finished with value: 0.7725835036777141 and parameters: {'n_a_d': 64, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.0001, 'batch_size': 2048, 'virtual_batch_size': 512, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_auc = 0.72768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:49:43,287] Trial 43 finished with value: 0.7777035331663165 and parameters: {'n_a_d': 128, 'n_steps': 10, 'gamma': 0.05, 'lambda': 0.0001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.4, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 21 and best_val_auc = 0.69586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:50:11,654] Trial 44 finished with value: 0.7681611903122008 and parameters: {'n_a_d': 64, 'n_steps': 10, 'gamma': 1.5, 'lambda': 0.0001, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.7}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 8 with best_epoch = 3 and best_val_auc = 0.62777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:50:19,267] Trial 45 finished with value: 0.7646512697573343 and parameters: {'n_a_d': 32, 'n_steps': 8, 'gamma': 0.1, 'lambda': 1e-05, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 17 and best_val_auc = 0.74173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:50:38,695] Trial 46 finished with value: 0.7867672872968082 and parameters: {'n_a_d': 32, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.025, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.6}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 34 and best_val_auc = 0.66891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:51:04,224] Trial 47 finished with value: 0.7699912661213388 and parameters: {'n_a_d': 8, 'n_steps': 10, 'gamma': 0.1, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 128, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 14 and best_val_auc = 0.67949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:52:18,353] Trial 48 finished with value: 0.7649096243214941 and parameters: {'n_a_d': 256, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-07, 'batch_size': 4096, 'virtual_batch_size': 2028, 'lr': 0.01, 'gamma_decay': 0.4, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 10 and best_val_auc = 0.60984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:53:37,244] Trial 49 finished with value: 0.7683990360344543 and parameters: {'n_a_d': 256, 'n_steps': 10, 'gamma': 2.0, 'lambda': 0.001, 'batch_size': 16384, 'virtual_batch_size': 2028, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 23 and best_val_auc = 0.75715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:54:25,351] Trial 50 finished with value: 0.7824761934419902 and parameters: {'n_a_d': 128, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 256, 'lr': 0.025, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 31 and best_val_auc = 0.76261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:54:54,511] Trial 51 finished with value: 0.7840787433801245 and parameters: {'n_a_d': 32, 'n_steps': 7, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.025, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.6}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 7 with best_epoch = 2 and best_val_auc = 0.6039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:55:08,276] Trial 52 finished with value: 0.7624349147154809 and parameters: {'n_a_d': 128, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0, 'batch_size': 4096, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.98}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 6 and best_val_auc = 0.63982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:55:21,356] Trial 53 finished with value: 0.7668657476366657 and parameters: {'n_a_d': 64, 'n_steps': 9, 'gamma': 2.0, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.025, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.6}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 15 and best_val_auc = 0.65933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:55:36,275] Trial 54 finished with value: 0.763320481306358 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 1.0, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.01, 'gamma_decay': 0.4, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_auc = 0.70304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:56:36,375] Trial 55 finished with value: 0.770602412559674 and parameters: {'n_a_d': 128, 'n_steps': 7, 'gamma': 1.5, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 256, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 6 with best_epoch = 1 and best_val_auc = 0.54555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:56:44,806] Trial 56 finished with value: 0.7656264012584442 and parameters: {'n_a_d': 64, 'n_steps': 8, 'gamma': 1.5, 'lambda': 1e-05, 'batch_size': 32768, 'virtual_batch_size': 128, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 8 with best_epoch = 3 and best_val_auc = 0.63231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:56:54,007] Trial 57 finished with value: 0.7668523863786045 and parameters: {'n_a_d': 64, 'n_steps': 7, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 23 and best_val_auc = 0.75968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:57:17,330] Trial 58 finished with value: 0.7789970049452036 and parameters: {'n_a_d': 32, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.05, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.6}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 25 and best_val_auc = 0.72649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:57:44,452] Trial 59 finished with value: 0.7759345752615341 and parameters: {'n_a_d': 16, 'n_steps': 8, 'gamma': 0.5, 'lambda': 0, 'batch_size': 1024, 'virtual_batch_size': 2028, 'lr': 0.05, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 33 and best_val_auc = 0.73297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:58:11,789] Trial 60 finished with value: 0.7872156620057822 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-07, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 14 and best_val_auc = 0.69715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:58:44,659] Trial 61 finished with value: 0.7715280157346595 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 0.01, 'lambda': 1e-07, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 34 and best_val_auc = 0.72531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:59:12,316] Trial 62 finished with value: 0.7938451660474837 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-07, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 26 and best_val_auc = 0.74713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:59:33,270] Trial 63 finished with value: 0.7840244135973617 and parameters: {'n_a_d': 16, 'n_steps': 9, 'gamma': 0.01, 'lambda': 1e-07, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 5 and best_val_auc = 0.66772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 10:59:51,038] Trial 64 finished with value: 0.7658109476190725 and parameters: {'n_a_d': 128, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-07, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.7}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 14 and best_val_auc = 0.6496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:00:04,067] Trial 65 finished with value: 0.7634895657837636 and parameters: {'n_a_d': 24, 'n_steps': 8, 'gamma': 1.0, 'lambda': 1e-07, 'batch_size': 4096, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 12 and best_val_auc = 0.68623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:00:18,506] Trial 66 finished with value: 0.7682143128578087 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.5, 'lambda': 1e-07, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.9, 'mask_type': 'sparsemax', 'batch_momentum': 0.98}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 28 and best_val_auc = 0.72253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:00:53,555] Trial 67 finished with value: 0.7769083898567614 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-07, 'batch_size': 1024, 'virtual_batch_size': 256, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 9 and best_val_auc = 0.67573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:01:06,787] Trial 68 finished with value: 0.7656551479718443 and parameters: {'n_a_d': 32, 'n_steps': 8, 'gamma': 1.5, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 5 and best_val_auc = 0.67779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:01:17,319] Trial 69 finished with value: 0.7648721610308643 and parameters: {'n_a_d': 24, 'n_steps': 8, 'gamma': 0.01, 'lambda': 1e-07, 'batch_size': 2048, 'virtual_batch_size': 128, 'lr': 0.025, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_auc = 0.71636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:01:44,645] Trial 70 finished with value: 0.7692279735968482 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-07, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.005, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.6}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 7 with best_epoch = 2 and best_val_auc = 0.57961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:01:50,746] Trial 71 finished with value: 0.7622054900182713 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.05, 'lambda': 0.1, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 21 and best_val_auc = 0.73336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:02:35,568] Trial 72 finished with value: 0.782151490458789 and parameters: {'n_a_d': 128, 'n_steps': 9, 'gamma': 0.8, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.05, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 27 and best_val_auc = 0.75778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:04:36,377] Trial 73 finished with value: 0.7863748267243396 and parameters: {'n_a_d': 256, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.005, 'gamma_decay': 0.9, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 6 and best_val_auc = 0.68113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:04:48,547] Trial 74 finished with value: 0.770786612471956 and parameters: {'n_a_d': 64, 'n_steps': 7, 'gamma': 1.5, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 14 and best_val_auc = 0.60363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:05:02,923] Trial 75 finished with value: 0.7666720364734948 and parameters: {'n_a_d': 32, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 8192, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 25 and best_val_auc = 0.59675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:05:21,236] Trial 76 finished with value: 0.764981085539589 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-07, 'batch_size': 16384, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.9, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 33 and best_val_auc = 0.75372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:06:35,649] Trial 77 finished with value: 0.7868435550541774 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 20 and best_val_auc = 0.70355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:07:28,896] Trial 78 finished with value: 0.7659857921830355 and parameters: {'n_a_d': 128, 'n_steps': 6, 'gamma': 0.8, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.9, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 14 and best_val_auc = 0.71411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:08:09,180] Trial 79 finished with value: 0.771375599320239 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 1.2, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.05, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.7}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 16 and best_val_auc = 0.72525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:08:58,202] Trial 80 finished with value: 0.768461835647449 and parameters: {'n_a_d': 128, 'n_steps': 7, 'gamma': 0.5, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 128, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 31 and best_val_auc = 0.7527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:10:02,886] Trial 81 finished with value: 0.7871717672182849 and parameters: {'n_a_d': 128, 'n_steps': 9, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.98}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 22 and best_val_auc = 0.72323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:11:56,083] Trial 82 finished with value: 0.7711090983485394 and parameters: {'n_a_d': 256, 'n_steps': 8, 'gamma': 1.5, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.01, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 9 and best_val_auc = 0.63505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:12:10,909] Trial 83 finished with value: 0.7650087289837725 and parameters: {'n_a_d': 64, 'n_steps': 9, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.005, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.98}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 27 and best_val_auc = 0.75505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:13:11,847] Trial 84 finished with value: 0.7896954714357765 and parameters: {'n_a_d': 128, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.98}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 34 and best_val_auc = 0.75125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:13:39,204] Trial 85 finished with value: 0.7889366058765676 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 1.5, 'lambda': 1e-07, 'batch_size': 1024, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 34 and best_val_auc = 0.73882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:14:00,913] Trial 86 finished with value: 0.7939029806624004 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 11 and best_val_auc = 0.6788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:14:17,170] Trial 87 finished with value: 0.7605015162411598 and parameters: {'n_a_d': 32, 'n_steps': 10, 'gamma': 1.5, 'lambda': 1e-07, 'batch_size': 1024, 'virtual_batch_size': 128, 'lr': 0.02, 'gamma_decay': 0.4, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 8 with best_epoch = 3 and best_val_auc = 0.58839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:14:22,177] Trial 88 finished with value: 0.7616163896710744 and parameters: {'n_a_d': 8, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 18 and best_val_auc = 0.70811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:14:36,581] Trial 89 finished with value: 0.7682465552078535 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.1, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 10 and best_val_auc = 0.65346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:14:49,403] Trial 90 finished with value: 0.761116749313569 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 1.5, 'lambda': 0.001, 'batch_size': 1024, 'virtual_batch_size': 512, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 15 and best_val_auc = 0.69197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:15:04,691] Trial 91 finished with value: 0.7747769162968068 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 1.5, 'lambda': 0.01, 'batch_size': 1024, 'virtual_batch_size': 2028, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.6}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_auc = 0.76617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:16:13,519] Trial 92 finished with value: 0.7897502604431982 and parameters: {'n_a_d': 128, 'n_steps': 7, 'gamma': 1.5, 'lambda': 1e-07, 'batch_size': 1024, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.98}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 18 and best_val_auc = 0.70784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:17:01,737] Trial 93 finished with value: 0.7673487454451796 and parameters: {'n_a_d': 128, 'n_steps': 7, 'gamma': 1.5, 'lambda': 1e-05, 'batch_size': 1024, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 6 and best_val_auc = 0.57519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:17:09,659] Trial 94 finished with value: 0.7647597732292171 and parameters: {'n_a_d': 24, 'n_steps': 8, 'gamma': 1.5, 'lambda': 1e-07, 'batch_size': 16384, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 12 and best_val_auc = 0.73002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:17:45,058] Trial 95 finished with value: 0.7778015256993055 and parameters: {'n_a_d': 128, 'n_steps': 6, 'gamma': 1.5, 'lambda': 1e-07, 'batch_size': 1024, 'virtual_batch_size': 2028, 'lr': 0.05, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.98}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 17 and best_val_auc = 0.7292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:18:08,284] Trial 96 finished with value: 0.7709762175765429 and parameters: {'n_a_d': 64, 'n_steps': 8, 'gamma': 1.0, 'lambda': 1e-07, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.98}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 33 and best_val_auc = 0.77613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:18:45,222] Trial 97 finished with value: 0.7849488248106845 and parameters: {'n_a_d': 64, 'n_steps': 8, 'gamma': 0.01, 'lambda': 1e-05, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.9, 'mask_type': 'sparsemax', 'batch_momentum': 0.7}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 6 and best_val_auc = 0.55997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:19:15,365] Trial 98 finished with value: 0.7677003098560539 and parameters: {'n_a_d': 128, 'n_steps': 7, 'gamma': 1.5, 'lambda': 1e-07, 'batch_size': 32768, 'virtual_batch_size': 1024, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.98}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 6 and best_val_auc = 0.68591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:19:25,362] Trial 99 finished with value: 0.7671688351592987 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 1.5, 'lambda': 0, 'batch_size': 1024, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.9, 'mask_type': 'entmax', 'batch_momentum': 0.98}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 13 and best_val_auc = 0.74542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:19:48,862] Trial 100 finished with value: 0.7750398814577235 and parameters: {'n_a_d': 64, 'n_steps': 6, 'gamma': 0.5, 'lambda': 0.001, 'batch_size': 1024, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.98}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 34 and best_val_auc = 0.73313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:20:16,656] Trial 101 finished with value: 0.7847417722461161 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 256, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.7}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 26 and best_val_auc = 0.64895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:20:34,427] Trial 102 finished with value: 0.772969289230038 and parameters: {'n_a_d': 8, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.4, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 30 and best_val_auc = 0.7522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:21:04,192] Trial 103 finished with value: 0.796248239606956 and parameters: {'n_a_d': 32, 'n_steps': 8, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 256, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 26 and best_val_auc = 0.76662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:21:35,670] Trial 104 finished with value: 0.7886731728205651 and parameters: {'n_a_d': 32, 'n_steps': 6, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 1024, 'virtual_batch_size': 256, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 18 and best_val_auc = 0.75217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:21:57,966] Trial 105 finished with value: 0.7861886381788448 and parameters: {'n_a_d': 32, 'n_steps': 8, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 1024, 'virtual_batch_size': 256, 'lr': 0.05, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 34 and best_val_auc = 0.69861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:22:27,094] Trial 106 finished with value: 0.7693937454137768 and parameters: {'n_a_d': 32, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 256, 'lr': 0.005, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 27 and best_val_auc = 0.7585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:22:58,565] Trial 107 finished with value: 0.783134958164449 and parameters: {'n_a_d': 32, 'n_steps': 7, 'gamma': 2.0, 'lambda': 0.001, 'batch_size': 1024, 'virtual_batch_size': 256, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 34 and best_val_auc = 0.70091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:23:26,394] Trial 108 finished with value: 0.7745220986260373 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 1.5, 'lambda': 1e-07, 'batch_size': 1024, 'virtual_batch_size': 1024, 'lr': 0.005, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 34 and best_val_auc = 0.73468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:23:54,691] Trial 109 finished with value: 0.7708806695936274 and parameters: {'n_a_d': 32, 'n_steps': 5, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 4096, 'virtual_batch_size': 256, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 9 with best_epoch = 4 and best_val_auc = 0.59006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:24:04,753] Trial 110 finished with value: 0.7617518415777262 and parameters: {'n_a_d': 32, 'n_steps': 5, 'gamma': 1.5, 'lambda': 1e-06, 'batch_size': 1024, 'virtual_batch_size': 256, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 23 and best_val_auc = 0.74593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:24:25,467] Trial 111 finished with value: 0.7929490779934528 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.05, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 15 and best_val_auc = 0.74102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:24:42,250] Trial 112 finished with value: 0.7796517655281552 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 1024, 'virtual_batch_size': 2028, 'lr': 0.05, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 16 and best_val_auc = 0.73089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:24:59,430] Trial 113 finished with value: 0.7759243913201984 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.05, 'lambda': 1e-07, 'batch_size': 1024, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.7}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 12 and best_val_auc = 0.56923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:25:12,165] Trial 114 finished with value: 0.7643214466779706 and parameters: {'n_a_d': 32, 'n_steps': 7, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 16384, 'virtual_batch_size': 2028, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 23 and best_val_auc = 0.63086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:26:17,230] Trial 115 finished with value: 0.7678146792822045 and parameters: {'n_a_d': 128, 'n_steps': 7, 'gamma': 0.5, 'lambda': 1e-07, 'batch_size': 16384, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.98}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 24 and best_val_auc = 0.74627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:26:40,920] Trial 116 finished with value: 0.7740482136500115 and parameters: {'n_a_d': 8, 'n_steps': 7, 'gamma': 0.1, 'lambda': 1e-06, 'batch_size': 1024, 'virtual_batch_size': 256, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 17 and best_val_auc = 0.74198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:27:20,658] Trial 117 finished with value: 0.7776298495261608 and parameters: {'n_a_d': 128, 'n_steps': 9, 'gamma': 0.01, 'lambda': 1e-05, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.01, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 26 and best_val_auc = 0.7243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:27:47,645] Trial 118 finished with value: 0.7635081539659528 and parameters: {'n_a_d': 32, 'n_steps': 9, 'gamma': 0.01, 'lambda': 1e-07, 'batch_size': 2048, 'virtual_batch_size': 256, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 29 and best_val_auc = 0.58602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:28:17,474] Trial 119 finished with value: 0.7700383130805201 and parameters: {'n_a_d': 32, 'n_steps': 7, 'gamma': 0.01, 'lambda': 0.1, 'batch_size': 2048, 'virtual_batch_size': 256, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 13 and best_val_auc = 0.72591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:28:35,006] Trial 120 finished with value: 0.7714266568343798 and parameters: {'n_a_d': 32, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 128, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 5 and best_val_auc = 0.60657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:29:16,646] Trial 121 finished with value: 0.7659957752115883 and parameters: {'n_a_d': 256, 'n_steps': 7, 'gamma': 0.8, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 256, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 34 and best_val_auc = 0.75393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:29:43,351] Trial 122 finished with value: 0.7831927349452631 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.8, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 17 and best_val_auc = 0.59246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:29:59,585] Trial 123 finished with value: 0.7631328949083113 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-07, 'batch_size': 32768, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.7}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 21 and best_val_auc = 0.74852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:30:52,693] Trial 124 finished with value: 0.7887717680665621 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.9, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 14 and best_val_auc = 0.69816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:31:31,053] Trial 125 finished with value: 0.7699043567481917 and parameters: {'n_a_d': 128, 'n_steps': 7, 'gamma': 0.01, 'lambda': 0.1, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.9, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 13 and best_val_auc = 0.63725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:31:44,992] Trial 126 finished with value: 0.7634943853649564 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.005, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 6 and best_val_auc = 0.67403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:31:58,612] Trial 127 finished with value: 0.7612707133648725 and parameters: {'n_a_d': 32, 'n_steps': 7, 'gamma': 0.8, 'lambda': 1e-06, 'batch_size': 1024, 'virtual_batch_size': 128, 'lr': 0.04, 'gamma_decay': 0.4, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 9 with best_epoch = 4 and best_val_auc = 0.65711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:32:38,206] Trial 128 finished with value: 0.7646883959332507 and parameters: {'n_a_d': 256, 'n_steps': 7, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 12 and best_val_auc = 0.72583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:32:53,000] Trial 129 finished with value: 0.7637101559487354 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 1.0, 'lambda': 1e-07, 'batch_size': 1024, 'virtual_batch_size': 4096, 'lr': 0.02, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_auc = 0.69971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:33:21,579] Trial 130 finished with value: 0.7658723825297054 and parameters: {'n_a_d': 24, 'n_steps': 8, 'gamma': 1.5, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 256, 'lr': 0.05, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 26 and best_val_auc = 0.68733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:34:17,936] Trial 131 finished with value: 0.7658204340045388 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 2.0, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.005, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 20 and best_val_auc = 0.72235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:34:35,904] Trial 132 finished with value: 0.782209656034321 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.8, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.9, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 8 and best_val_auc = 0.69205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:34:49,555] Trial 133 finished with value: 0.7731438196908197 and parameters: {'n_a_d': 32, 'n_steps': 10, 'gamma': 1.5, 'lambda': 1e-07, 'batch_size': 1024, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 35 with value: 0.7985649154799528.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 29 and best_val_auc = 0.75682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:35:13,884] Trial 134 finished with value: 0.8003872482245278 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 9 with best_epoch = 4 and best_val_auc = 0.56046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:35:20,475] Trial 135 finished with value: 0.7663497273597232 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 8192, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 16 and best_val_auc = 0.6949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:35:37,839] Trial 136 finished with value: 0.7701626637038784 and parameters: {'n_a_d': 32, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.4, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_auc = 0.74746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:36:00,061] Trial 137 finished with value: 0.790489220458204 and parameters: {'n_a_d': 16, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 25 and best_val_auc = 0.74581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:36:21,367] Trial 138 finished with value: 0.7822929654239568 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.9}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 17 and best_val_auc = 0.61949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:36:35,985] Trial 139 finished with value: 0.7647356352113083 and parameters: {'n_a_d': 16, 'n_steps': 10, 'gamma': 1.5, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.02, 'gamma_decay': 0.9, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_auc = 0.74834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:36:57,472] Trial 140 finished with value: 0.7809903659453845 and parameters: {'n_a_d': 16, 'n_steps': 7, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 31 and best_val_auc = 0.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:37:33,496] Trial 141 finished with value: 0.7842417683438575 and parameters: {'n_a_d': 64, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 4096, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 26 and best_val_auc = 0.76452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:38:07,395] Trial 142 finished with value: 0.7867795720050206 and parameters: {'n_a_d': 32, 'n_steps': 7, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 1024, 'virtual_batch_size': 256, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 23 and best_val_auc = 0.73646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:38:23,971] Trial 143 finished with value: 0.7829094678841247 and parameters: {'n_a_d': 8, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 512, 'lr': 0.04, 'gamma_decay': 0.9, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 12 and best_val_auc = 0.69881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:38:43,378] Trial 144 finished with value: 0.7638745916731736 and parameters: {'n_a_d': 64, 'n_steps': 7, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.005, 'gamma_decay': 0.9, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 8 with best_epoch = 3 and best_val_auc = 0.64048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:38:50,083] Trial 145 finished with value: 0.7614061823146457 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.8, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.05, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.7}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 13 and best_val_auc = 0.74034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:39:59,571] Trial 146 finished with value: 0.7708265972719912 and parameters: {'n_a_d': 256, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 1024, 'virtual_batch_size': 2028, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 22 and best_val_auc = 0.73798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:40:19,051] Trial 147 finished with value: 0.769980367655406 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.05, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.05, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 29 and best_val_auc = 0.75523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:40:44,167] Trial 148 finished with value: 0.7865047783592393 and parameters: {'n_a_d': 24, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.0001, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.05, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.98}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 21 and best_val_auc = 0.73811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:41:04,098] Trial 149 finished with value: 0.7848361160760855 and parameters: {'n_a_d': 32, 'n_steps': 9, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.05, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 5 and best_val_auc = 0.63589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:41:16,049] Trial 150 finished with value: 0.7645047262041386 and parameters: {'n_a_d': 32, 'n_steps': 5, 'gamma': 0.8, 'lambda': 0.01, 'batch_size': 1024, 'virtual_batch_size': 256, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.9}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 34 and best_val_auc = 0.75739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:41:40,213] Trial 151 finished with value: 0.7924629849513201 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 28 and best_val_auc = 0.72869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:42:09,254] Trial 152 finished with value: 0.7734357792319815 and parameters: {'n_a_d': 32, 'n_steps': 8, 'gamma': 0.5, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 256, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 21 and best_val_auc = 0.74853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:42:52,067] Trial 153 finished with value: 0.794703424514601 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 29 and best_val_auc = 0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:43:17,026] Trial 154 finished with value: 0.7713188581446911 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.005, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 11 and best_val_auc = 0.58209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:43:28,234] Trial 155 finished with value: 0.7669057702075347 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 1.5, 'lambda': 0, 'batch_size': 32768, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 24 and best_val_auc = 0.77164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:44:20,380] Trial 156 finished with value: 0.7914628640684456 and parameters: {'n_a_d': 128, 'n_steps': 9, 'gamma': 0.1, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 11 and best_val_auc = 0.71242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:44:49,182] Trial 157 finished with value: 0.7659762997887473 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 1.0, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 27 and best_val_auc = 0.74759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:45:44,813] Trial 158 finished with value: 0.7824533740303887 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 0.05, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 134 with value: 0.8003872482245278.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 28 and best_val_auc = 0.75856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:46:08,127] Trial 159 finished with value: 0.8033985960069625 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 159 with value: 0.8033985960069625.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 9 with best_epoch = 4 and best_val_auc = 0.58774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:46:30,170] Trial 160 finished with value: 0.7673126583962041 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 0.1, 'lambda': 0.001, 'batch_size': 16384, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.6}. Best is trial 159 with value: 0.8033985960069625.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 22 and best_val_auc = 0.7517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:47:22,360] Trial 161 finished with value: 0.7753818419936018 and parameters: {'n_a_d': 128, 'n_steps': 7, 'gamma': 0.1, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 128, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 159 with value: 0.8033985960069625.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 31 and best_val_auc = 0.76732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:47:45,588] Trial 162 finished with value: 0.8133091520605825 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 8 and best_val_auc = 0.64076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:47:55,476] Trial 163 finished with value: 0.7649337960496929 and parameters: {'n_a_d': 24, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 4096, 'virtual_batch_size': 512, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 31 and best_val_auc = 0.76732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:48:18,580] Trial 164 finished with value: 0.8133091520605825 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 15 and best_val_auc = 0.69728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:48:32,974] Trial 165 finished with value: 0.7707989570370413 and parameters: {'n_a_d': 24, 'n_steps': 8, 'gamma': 1.2, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 8 with best_epoch = 3 and best_val_auc = 0.58928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:48:37,673] Trial 166 finished with value: 0.7653869735718609 and parameters: {'n_a_d': 8, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 32768, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 28 and best_val_auc = 0.75856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:49:01,034] Trial 167 finished with value: 0.8033985960069625 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 17 and best_val_auc = 0.63636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:49:15,612] Trial 168 finished with value: 0.7633250743934273 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 16384, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 30 and best_val_auc = 0.74312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:49:39,785] Trial 169 finished with value: 0.7755882714562063 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.4, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 31 and best_val_auc = 0.75631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:50:01,912] Trial 170 finished with value: 0.7849581656743537 and parameters: {'n_a_d': 16, 'n_steps': 10, 'gamma': 0.1, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 12 and best_val_auc = 0.72312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:50:14,191] Trial 171 finished with value: 0.7716277339010771 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.01, 'lambda': 1e-05, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 34 and best_val_auc = 0.75924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:50:43,170] Trial 172 finished with value: 0.7986531144025776 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 128, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 6 with best_epoch = 1 and best_val_auc = 0.57893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:50:49,773] Trial 173 finished with value: 0.7771594594926694 and parameters: {'n_a_d': 32, 'n_steps': 10, 'gamma': 1.5, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 128, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 26 and best_val_auc = 0.73658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:51:13,305] Trial 174 finished with value: 0.7781318412714037 and parameters: {'n_a_d': 32, 'n_steps': 10, 'gamma': 0.5, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_auc = 0.76344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:51:41,941] Trial 175 finished with value: 0.7720456761979918 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 128, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_auc = 0.74682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:53:47,280] Trial 176 finished with value: 0.7811189118853991 and parameters: {'n_a_d': 256, 'n_steps': 7, 'gamma': 0.01, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.005, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 31 and best_val_auc = 0.74991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:54:22,727] Trial 177 finished with value: 0.7877088609507181 and parameters: {'n_a_d': 64, 'n_steps': 6, 'gamma': 0.01, 'lambda': 1e-05, 'batch_size': 4096, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 22 and best_val_auc = 0.73401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:54:41,339] Trial 178 finished with value: 0.7671974482230809 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.025, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.6}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 9 with best_epoch = 4 and best_val_auc = 0.64337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:54:49,199] Trial 179 finished with value: 0.7640673775103388 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 1.2, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.05, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 31 and best_val_auc = 0.76792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:55:13,290] Trial 180 finished with value: 0.8117582762024057 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 15 and best_val_auc = 0.61517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:55:27,922] Trial 181 finished with value: 0.7672421114259675 and parameters: {'n_a_d': 32, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 32768, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 29 and best_val_auc = 0.76581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:55:52,406] Trial 182 finished with value: 0.7917743315725516 and parameters: {'n_a_d': 24, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 26 and best_val_auc = 0.74543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:56:17,823] Trial 183 finished with value: 0.7826509900719175 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 256, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_auc = 0.74347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:56:41,145] Trial 184 finished with value: 0.7705221707967328 and parameters: {'n_a_d': 24, 'n_steps': 7, 'gamma': 0.05, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 6 and best_val_auc = 0.62607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:56:51,903] Trial 185 finished with value: 0.76247685911469 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-05, 'batch_size': 2048, 'virtual_batch_size': 128, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 30 and best_val_auc = 0.76817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:57:50,768] Trial 186 finished with value: 0.7934961249449163 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 9 with best_epoch = 4 and best_val_auc = 0.64678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:57:57,175] Trial 187 finished with value: 0.7666429002084229 and parameters: {'n_a_d': 16, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.05, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 20 and best_val_auc = 0.72593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:58:15,764] Trial 188 finished with value: 0.7741542845591342 and parameters: {'n_a_d': 16, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 512, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 28 and best_val_auc = 0.76104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:59:13,285] Trial 189 finished with value: 0.7880692269758616 and parameters: {'n_a_d': 128, 'n_steps': 6, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.98}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 16 and best_val_auc = 0.75309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 11:59:50,145] Trial 190 finished with value: 0.7835357134595129 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 0.01, 'lambda': 1e-05, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 20 and best_val_auc = 0.74247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:01:24,064] Trial 191 finished with value: 0.7833116445275196 and parameters: {'n_a_d': 256, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 31 and best_val_auc = 0.76002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:03:29,672] Trial 192 finished with value: 0.7841104402369469 and parameters: {'n_a_d': 256, 'n_steps': 10, 'gamma': 1.5, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 7 with best_epoch = 2 and best_val_auc = 0.59231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:03:35,987] Trial 193 finished with value: 0.7650420176606547 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 25 and best_val_auc = 0.74852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:05:30,261] Trial 194 finished with value: 0.7815485640091359 and parameters: {'n_a_d': 256, 'n_steps': 8, 'gamma': 1.0, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.025, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 18 and best_val_auc = 0.76558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:06:16,376] Trial 195 finished with value: 0.765154800808753 and parameters: {'n_a_d': 128, 'n_steps': 9, 'gamma': 0.1, 'lambda': 0.001, 'batch_size': 1024, 'virtual_batch_size': 1024, 'lr': 0.05, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_auc = 0.75583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:06:37,141] Trial 196 finished with value: 0.7968381637126842 and parameters: {'n_a_d': 16, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 21 and best_val_auc = 0.7661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:07:22,549] Trial 197 finished with value: 0.7864062647365618 and parameters: {'n_a_d': 128, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.05, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 5 with best_epoch = 0 and best_val_auc = 0.53644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:07:26,469] Trial 198 finished with value: 0.7759146427136444 and parameters: {'n_a_d': 16, 'n_steps': 9, 'gamma': 0.8, 'lambda': 0.01, 'batch_size': 32768, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 31 and best_val_auc = 0.76425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:07:55,531] Trial 199 finished with value: 0.7896075243706949 and parameters: {'n_a_d': 32, 'n_steps': 7, 'gamma': 0.01, 'lambda': 0.0001, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 33 and best_val_auc = 0.73775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:08:19,956] Trial 200 finished with value: 0.7870299034152282 and parameters: {'n_a_d': 24, 'n_steps': 6, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.7}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_auc = 0.71414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:08:48,032] Trial 201 finished with value: 0.7709818271627961 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.8, 'lambda': 0, 'batch_size': 2048, 'virtual_batch_size': 256, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 25 and best_val_auc = 0.7371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:09:21,725] Trial 202 finished with value: 0.7834709245099486 and parameters: {'n_a_d': 64, 'n_steps': 8, 'gamma': 0.1, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.7}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 34 and best_val_auc = 0.75534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:09:43,104] Trial 203 finished with value: 0.7763875669892615 and parameters: {'n_a_d': 16, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 8 with best_epoch = 3 and best_val_auc = 0.58363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:09:48,909] Trial 204 finished with value: 0.7644864711249687 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 8192, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.98}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 27 and best_val_auc = 0.7681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:11:48,949] Trial 205 finished with value: 0.7990888650666567 and parameters: {'n_a_d': 256, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 21 and best_val_auc = 0.76566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:13:29,597] Trial 206 finished with value: 0.7886619699431823 and parameters: {'n_a_d': 256, 'n_steps': 7, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.6}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 28 and best_val_auc = 0.75601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:15:35,104] Trial 207 finished with value: 0.7860463272471683 and parameters: {'n_a_d': 256, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.0001, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.01, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 11 and best_val_auc = 0.65046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:15:46,766] Trial 208 finished with value: 0.7648767130253672 and parameters: {'n_a_d': 24, 'n_steps': 7, 'gamma': 1.0, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 15 and best_val_auc = 0.63829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:16:30,501] Trial 209 finished with value: 0.7668181264366174 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 32768, 'virtual_batch_size': 4096, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 31 and best_val_auc = 0.73344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:16:48,765] Trial 210 finished with value: 0.7843716485176696 and parameters: {'n_a_d': 8, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.04, 'gamma_decay': 0.4, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 8 and best_val_auc = 0.69468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:17:13,753] Trial 211 finished with value: 0.766359233323075 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 256, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 12 and best_val_auc = 0.70924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:17:26,830] Trial 212 finished with value: 0.7648203466391533 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.03, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 21 and best_val_auc = 0.76276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:19:04,244] Trial 213 finished with value: 0.7836896636097401 and parameters: {'n_a_d': 256, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.7}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 5 and best_val_auc = 0.62616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:19:42,976] Trial 214 finished with value: 0.7635832002202814 and parameters: {'n_a_d': 256, 'n_steps': 7, 'gamma': 1.5, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 11 and best_val_auc = 0.69892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:19:55,006] Trial 215 finished with value: 0.7733435244180912 and parameters: {'n_a_d': 24, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 1024, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 6 with best_epoch = 1 and best_val_auc = 0.62581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:19:59,428] Trial 216 finished with value: 0.7624908409298856 and parameters: {'n_a_d': 16, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.1, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.05, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 18 and best_val_auc = 0.65145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:20:15,990] Trial 217 finished with value: 0.7649852670331315 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 8192, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_auc = 0.72187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:21:13,599] Trial 218 finished with value: 0.7947636036272057 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 4096, 'virtual_batch_size': 4096, 'lr': 0.01, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 31 and best_val_auc = 0.72898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:22:11,957] Trial 219 finished with value: 0.7878719908697475 and parameters: {'n_a_d': 128, 'n_steps': 7, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 4096, 'virtual_batch_size': 4096, 'lr': 0.01, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 10 and best_val_auc = 0.68898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:22:23,960] Trial 220 finished with value: 0.7672591204744676 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.5, 'lambda': 1e-07, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.02, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 24 and best_val_auc = 0.77164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:23:14,180] Trial 221 finished with value: 0.7914628640684456 and parameters: {'n_a_d': 128, 'n_steps': 9, 'gamma': 0.1, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 12 and best_val_auc = 0.59937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:23:54,966] Trial 222 finished with value: 0.7655327903167878 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 16384, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_auc = 0.75675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:24:50,372] Trial 223 finished with value: 0.785130973643515 and parameters: {'n_a_d': 128, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 22 and best_val_auc = 0.70982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:25:10,264] Trial 224 finished with value: 0.7688742293022387 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.1, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 28 and best_val_auc = 0.73952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:26:10,129] Trial 225 finished with value: 0.7793518973898902 and parameters: {'n_a_d': 128, 'n_steps': 7, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 128, 'lr': 0.04, 'gamma_decay': 0.4, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 22 and best_val_auc = 0.73862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:27:48,840] Trial 226 finished with value: 0.781958015431069 and parameters: {'n_a_d': 256, 'n_steps': 8, 'gamma': 0.1, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 31 and best_val_auc = 0.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:28:44,832] Trial 227 finished with value: 0.7849913401647169 and parameters: {'n_a_d': 128, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.9, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 20 and best_val_auc = 0.6868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:29:11,588] Trial 228 finished with value: 0.7671790406938965 and parameters: {'n_a_d': 64, 'n_steps': 8, 'gamma': 0.01, 'lambda': 1e-05, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.005, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 5 with best_epoch = 0 and best_val_auc = 0.56965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:29:16,277] Trial 229 finished with value: 0.7628237003304349 and parameters: {'n_a_d': 24, 'n_steps': 6, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 9 with best_epoch = 4 and best_val_auc = 0.56438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:29:23,194] Trial 230 finished with value: 0.766418544463592 and parameters: {'n_a_d': 32, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0, 'batch_size': 16384, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 5 with best_epoch = 0 and best_val_auc = 0.57166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:29:33,131] Trial 231 finished with value: 0.7609769238544768 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 0.1, 'lambda': 0.1, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 32 and best_val_auc = 0.76934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:30:27,317] Trial 232 finished with value: 0.8100608509057907 and parameters: {'n_a_d': 128, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 15 and best_val_auc = 0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:30:42,421] Trial 233 finished with value: 0.7841922817360563 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 30 and best_val_auc = 0.75916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:31:06,376] Trial 234 finished with value: 0.7870725630631024 and parameters: {'n_a_d': 24, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.9, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 23 and best_val_auc = 0.76154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:32:50,386] Trial 235 finished with value: 0.7832364591890659 and parameters: {'n_a_d': 256, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-07, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.02, 'gamma_decay': 0.9, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 35 with best_epoch = 34 and best_val_auc = 0.7505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:33:14,835] Trial 236 finished with value: 0.7889916388910684 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-05, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.05, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 8 with best_epoch = 3 and best_val_auc = 0.53582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:33:20,895] Trial 237 finished with value: 0.7613595799395962 and parameters: {'n_a_d': 16, 'n_steps': 10, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 16384, 'virtual_batch_size': 256, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 15 and best_val_auc = 0.73104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:33:43,816] Trial 238 finished with value: 0.7700576346267143 and parameters: {'n_a_d': 64, 'n_steps': 9, 'gamma': 0.01, 'lambda': 1e-05, 'batch_size': 2048, 'virtual_batch_size': 2028, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 21 and best_val_auc = 0.75117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:35:20,699] Trial 239 finished with value: 0.7789461507285131 and parameters: {'n_a_d': 256, 'n_steps': 8, 'gamma': 0.01, 'lambda': 0.01, 'batch_size': 2048, 'virtual_batch_size': 4096, 'lr': 0.04, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.9}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 9 and best_val_auc = 0.67363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:35:37,063] Trial 240 finished with value: 0.7664582500704895 and parameters: {'n_a_d': 64, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.8, 'mask_type': 'entmax', 'batch_momentum': 0.6}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 16 and best_val_auc = 0.75947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:36:15,987] Trial 241 finished with value: 0.7851759920674953 and parameters: {'n_a_d': 128, 'n_steps': 10, 'gamma': 0.01, 'lambda': 1e-05, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 17 and best_val_auc = 0.73707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:36:54,918] Trial 242 finished with value: 0.7719831510881705 and parameters: {'n_a_d': 128, 'n_steps': 10, 'gamma': 0.1, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.025, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 17 and best_val_auc = 0.72247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:37:32,803] Trial 243 finished with value: 0.7726891944795212 and parameters: {'n_a_d': 128, 'n_steps': 8, 'gamma': 1.2, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.05, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.98}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 11 and best_val_auc = 0.67572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:37:46,673] Trial 244 finished with value: 0.7644483967480696 and parameters: {'n_a_d': 16, 'n_steps': 8, 'gamma': 0.01, 'lambda': 1e-06, 'batch_size': 2048, 'virtual_batch_size': 256, 'lr': 0.04, 'gamma_decay': 0.4, 'mask_type': 'sparsemax', 'batch_momentum': 0.8}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 29 and best_val_auc = 0.7673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:38:46,173] Trial 245 finished with value: 0.7837860732274498 and parameters: {'n_a_d': 128, 'n_steps': 10, 'gamma': 1.5, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.6}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 9 with best_epoch = 4 and best_val_auc = 0.6692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:38:53,403] Trial 246 finished with value: 0.7648203466391533 and parameters: {'n_a_d': 16, 'n_steps': 7, 'gamma': 0.01, 'lambda': 0.0001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'entmax', 'batch_momentum': 0.98}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 5 and best_val_auc = 0.58009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:39:00,232] Trial 247 finished with value: 0.7613594388053737 and parameters: {'n_a_d': 8, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.01, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 20 and best_val_auc = 0.72978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:39:19,056] Trial 248 finished with value: 0.7771020459130739 and parameters: {'n_a_d': 24, 'n_steps': 10, 'gamma': 0.1, 'lambda': 0.001, 'batch_size': 2048, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n",
      "<ipython-input-6-28ed69af07b4>:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  'n_steps': trial.suggest_int('n_steps', 3, 10, 1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 21 and best_val_auc = 0.76716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "[I 2024-11-18 12:40:10,671] Trial 249 finished with value: 0.7958340057612099 and parameters: {'n_a_d': 128, 'n_steps': 9, 'gamma': 0.01, 'lambda': 0.001, 'batch_size': 1024, 'virtual_batch_size': 1024, 'lr': 0.04, 'gamma_decay': 0.95, 'mask_type': 'sparsemax', 'batch_momentum': 0.95}. Best is trial 162 with value: 0.8133091520605825.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, \n",
    "               timeout=60*60*6, \n",
    "               n_trials=250, \n",
    "               gc_after_trial=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ec8a1-0e32-43ea-9f4b-3c9f4c70fa43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_a_d': 24,\n",
       " 'n_steps': 9,\n",
       " 'gamma': 0.01,\n",
       " 'lambda': 0.01,\n",
       " 'batch_size': 2048,\n",
       " 'virtual_batch_size': 1024,\n",
       " 'lr': 0.04,\n",
       " 'gamma_decay': 0.95,\n",
       " 'mask_type': 'entmax',\n",
       " 'batch_momentum': 0.95}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94520549-e76d-4588-bb29-ebac9586d671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# Define the model with optimized parameters EU\n",
    "clf = TabNetClassifier(\n",
    "    n_d=24,  # Set decision dimension\n",
    "    n_a=24,  # Set attention dimension\n",
    "    n_steps=9,  # Number of steps in the network\n",
    "    gamma=0.01,  # Gamma parameter\n",
    "    lambda_sparse=0.01,  # Sparsity regularization\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=0.04),  # Learning rate\n",
    "    scheduler_params={\"step_size\": 10, \"gamma\": 0.95},  # Scheduler decay rate\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='entmax',  # Mask type\n",
    "    momentum=0.95  # Batch normalization momentum\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b03c5-da21-43d2-a3df-a0a239da05f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.97975 | train_auc: 0.58093 | train_balanced_accuracy: 0.51687 | val_auc: 0.5422  | val_balanced_accuracy: 0.50816 |  0:00:01s\n",
      "epoch 1  | loss: 0.74671 | train_auc: 0.56948 | train_balanced_accuracy: 0.516   | val_auc: 0.51327 | val_balanced_accuracy: 0.50915 |  0:00:02s\n",
      "epoch 2  | loss: 0.66839 | train_auc: 0.58935 | train_balanced_accuracy: 0.52015 | val_auc: 0.55285 | val_balanced_accuracy: 0.51125 |  0:00:04s\n",
      "epoch 3  | loss: 0.61697 | train_auc: 0.62762 | train_balanced_accuracy: 0.5202  | val_auc: 0.61796 | val_balanced_accuracy: 0.52108 |  0:00:05s\n",
      "epoch 4  | loss: 0.59314 | train_auc: 0.68386 | train_balanced_accuracy: 0.52716 | val_auc: 0.65065 | val_balanced_accuracy: 0.51201 |  0:00:06s\n",
      "epoch 5  | loss: 0.56818 | train_auc: 0.68029 | train_balanced_accuracy: 0.52369 | val_auc: 0.65081 | val_balanced_accuracy: 0.51536 |  0:00:08s\n",
      "epoch 6  | loss: 0.56258 | train_auc: 0.70441 | train_balanced_accuracy: 0.52475 | val_auc: 0.65815 | val_balanced_accuracy: 0.51288 |  0:00:09s\n",
      "epoch 7  | loss: 0.55471 | train_auc: 0.71524 | train_balanced_accuracy: 0.53092 | val_auc: 0.67874 | val_balanced_accuracy: 0.52156 |  0:00:10s\n",
      "epoch 8  | loss: 0.54315 | train_auc: 0.70434 | train_balanced_accuracy: 0.52661 | val_auc: 0.65249 | val_balanced_accuracy: 0.51043 |  0:00:12s\n",
      "epoch 9  | loss: 0.54018 | train_auc: 0.7309  | train_balanced_accuracy: 0.54362 | val_auc: 0.68309 | val_balanced_accuracy: 0.52802 |  0:00:13s\n",
      "epoch 10 | loss: 0.54572 | train_auc: 0.72239 | train_balanced_accuracy: 0.5343  | val_auc: 0.68671 | val_balanced_accuracy: 0.52109 |  0:00:14s\n",
      "epoch 11 | loss: 0.5337  | train_auc: 0.73374 | train_balanced_accuracy: 0.53474 | val_auc: 0.69233 | val_balanced_accuracy: 0.5263  |  0:00:16s\n",
      "epoch 12 | loss: 0.53388 | train_auc: 0.73833 | train_balanced_accuracy: 0.54233 | val_auc: 0.69205 | val_balanced_accuracy: 0.5242  |  0:00:17s\n",
      "epoch 13 | loss: 0.53295 | train_auc: 0.74804 | train_balanced_accuracy: 0.5539  | val_auc: 0.69911 | val_balanced_accuracy: 0.53192 |  0:00:18s\n",
      "epoch 14 | loss: 0.52654 | train_auc: 0.7383  | train_balanced_accuracy: 0.53312 | val_auc: 0.68869 | val_balanced_accuracy: 0.52136 |  0:00:19s\n",
      "epoch 15 | loss: 0.52534 | train_auc: 0.74069 | train_balanced_accuracy: 0.55523 | val_auc: 0.6935  | val_balanced_accuracy: 0.53827 |  0:00:21s\n",
      "epoch 16 | loss: 0.52091 | train_auc: 0.74585 | train_balanced_accuracy: 0.53639 | val_auc: 0.70176 | val_balanced_accuracy: 0.52188 |  0:00:22s\n",
      "epoch 17 | loss: 0.51703 | train_auc: 0.7568  | train_balanced_accuracy: 0.53797 | val_auc: 0.70568 | val_balanced_accuracy: 0.51841 |  0:00:23s\n",
      "epoch 18 | loss: 0.50883 | train_auc: 0.74999 | train_balanced_accuracy: 0.54068 | val_auc: 0.70381 | val_balanced_accuracy: 0.52894 |  0:00:25s\n",
      "epoch 19 | loss: 0.50979 | train_auc: 0.75761 | train_balanced_accuracy: 0.54035 | val_auc: 0.7208  | val_balanced_accuracy: 0.52701 |  0:00:26s\n",
      "epoch 20 | loss: 0.5091  | train_auc: 0.76326 | train_balanced_accuracy: 0.56672 | val_auc: 0.71359 | val_balanced_accuracy: 0.5506  |  0:00:27s\n",
      "epoch 21 | loss: 0.50673 | train_auc: 0.76125 | train_balanced_accuracy: 0.54178 | val_auc: 0.71788 | val_balanced_accuracy: 0.52552 |  0:00:28s\n",
      "epoch 22 | loss: 0.50289 | train_auc: 0.77069 | train_balanced_accuracy: 0.55001 | val_auc: 0.7156  | val_balanced_accuracy: 0.52734 |  0:00:30s\n",
      "epoch 23 | loss: 0.49121 | train_auc: 0.78257 | train_balanced_accuracy: 0.56656 | val_auc: 0.73636 | val_balanced_accuracy: 0.55126 |  0:00:31s\n",
      "epoch 24 | loss: 0.49262 | train_auc: 0.78848 | train_balanced_accuracy: 0.59027 | val_auc: 0.73766 | val_balanced_accuracy: 0.56326 |  0:00:32s\n",
      "epoch 25 | loss: 0.4859  | train_auc: 0.78524 | train_balanced_accuracy: 0.55591 | val_auc: 0.72928 | val_balanced_accuracy: 0.54037 |  0:00:34s\n",
      "epoch 26 | loss: 0.47615 | train_auc: 0.7952  | train_balanced_accuracy: 0.57871 | val_auc: 0.7477  | val_balanced_accuracy: 0.5558  |  0:00:35s\n",
      "epoch 27 | loss: 0.47716 | train_auc: 0.79101 | train_balanced_accuracy: 0.54626 | val_auc: 0.74299 | val_balanced_accuracy: 0.5257  |  0:00:36s\n",
      "epoch 28 | loss: 0.47653 | train_auc: 0.79155 | train_balanced_accuracy: 0.61337 | val_auc: 0.72509 | val_balanced_accuracy: 0.58449 |  0:00:37s\n",
      "epoch 29 | loss: 0.47365 | train_auc: 0.78978 | train_balanced_accuracy: 0.55076 | val_auc: 0.74359 | val_balanced_accuracy: 0.52802 |  0:00:39s\n",
      "epoch 30 | loss: 0.47022 | train_auc: 0.7812  | train_balanced_accuracy: 0.58362 | val_auc: 0.72807 | val_balanced_accuracy: 0.56624 |  0:00:40s\n",
      "epoch 31 | loss: 0.47484 | train_auc: 0.80075 | train_balanced_accuracy: 0.61828 | val_auc: 0.74285 | val_balanced_accuracy: 0.5927  |  0:00:41s\n",
      "epoch 32 | loss: 0.47092 | train_auc: 0.78211 | train_balanced_accuracy: 0.70005 | val_auc: 0.71374 | val_balanced_accuracy: 0.64806 |  0:00:42s\n",
      "epoch 33 | loss: 0.47039 | train_auc: 0.78453 | train_balanced_accuracy: 0.58844 | val_auc: 0.73243 | val_balanced_accuracy: 0.56757 |  0:00:44s\n",
      "epoch 34 | loss: 0.46099 | train_auc: 0.81723 | train_balanced_accuracy: 0.61229 | val_auc: 0.75506 | val_balanced_accuracy: 0.5754  |  0:00:45s\n",
      "epoch 35 | loss: 0.46416 | train_auc: 0.79082 | train_balanced_accuracy: 0.58672 | val_auc: 0.73572 | val_balanced_accuracy: 0.56903 |  0:00:46s\n",
      "epoch 36 | loss: 0.46021 | train_auc: 0.8028  | train_balanced_accuracy: 0.59134 | val_auc: 0.7547  | val_balanced_accuracy: 0.55998 |  0:00:47s\n",
      "epoch 37 | loss: 0.45593 | train_auc: 0.78966 | train_balanced_accuracy: 0.57891 | val_auc: 0.74123 | val_balanced_accuracy: 0.54232 |  0:00:49s\n",
      "epoch 38 | loss: 0.45081 | train_auc: 0.78785 | train_balanced_accuracy: 0.58941 | val_auc: 0.73966 | val_balanced_accuracy: 0.55096 |  0:00:50s\n",
      "epoch 39 | loss: 0.45214 | train_auc: 0.76146 | train_balanced_accuracy: 0.67404 | val_auc: 0.69057 | val_balanced_accuracy: 0.61765 |  0:00:51s\n",
      "epoch 40 | loss: 0.45064 | train_auc: 0.79513 | train_balanced_accuracy: 0.678   | val_auc: 0.71675 | val_balanced_accuracy: 0.62918 |  0:00:52s\n",
      "epoch 41 | loss: 0.4519  | train_auc: 0.79583 | train_balanced_accuracy: 0.63347 | val_auc: 0.7436  | val_balanced_accuracy: 0.59959 |  0:00:53s\n",
      "epoch 42 | loss: 0.4509  | train_auc: 0.72326 | train_balanced_accuracy: 0.6225  | val_auc: 0.66351 | val_balanced_accuracy: 0.58437 |  0:00:55s\n",
      "epoch 43 | loss: 0.44954 | train_auc: 0.80908 | train_balanced_accuracy: 0.63762 | val_auc: 0.74071 | val_balanced_accuracy: 0.58192 |  0:00:56s\n",
      "epoch 44 | loss: 0.44512 | train_auc: 0.81511 | train_balanced_accuracy: 0.60359 | val_auc: 0.75982 | val_balanced_accuracy: 0.5803  |  0:00:57s\n",
      "epoch 45 | loss: 0.44006 | train_auc: 0.81738 | train_balanced_accuracy: 0.6024  | val_auc: 0.75463 | val_balanced_accuracy: 0.56196 |  0:00:59s\n",
      "epoch 46 | loss: 0.43422 | train_auc: 0.81909 | train_balanced_accuracy: 0.63453 | val_auc: 0.75753 | val_balanced_accuracy: 0.59585 |  0:01:00s\n",
      "epoch 47 | loss: 0.43645 | train_auc: 0.81484 | train_balanced_accuracy: 0.64721 | val_auc: 0.75112 | val_balanced_accuracy: 0.60693 |  0:01:01s\n",
      "epoch 48 | loss: 0.43534 | train_auc: 0.80227 | train_balanced_accuracy: 0.61276 | val_auc: 0.74619 | val_balanced_accuracy: 0.59668 |  0:01:02s\n",
      "epoch 49 | loss: 0.43138 | train_auc: 0.81945 | train_balanced_accuracy: 0.67882 | val_auc: 0.73122 | val_balanced_accuracy: 0.61305 |  0:01:04s\n",
      "epoch 50 | loss: 0.43225 | train_auc: 0.84022 | train_balanced_accuracy: 0.68006 | val_auc: 0.73861 | val_balanced_accuracy: 0.61561 |  0:01:05s\n",
      "epoch 51 | loss: 0.42666 | train_auc: 0.80714 | train_balanced_accuracy: 0.61017 | val_auc: 0.73543 | val_balanced_accuracy: 0.57219 |  0:01:06s\n",
      "epoch 52 | loss: 0.42546 | train_auc: 0.75733 | train_balanced_accuracy: 0.66649 | val_auc: 0.68222 | val_balanced_accuracy: 0.60889 |  0:01:07s\n",
      "epoch 53 | loss: 0.42259 | train_auc: 0.8116  | train_balanced_accuracy: 0.72815 | val_auc: 0.71758 | val_balanced_accuracy: 0.65015 |  0:01:09s\n",
      "epoch 54 | loss: 0.42405 | train_auc: 0.83264 | train_balanced_accuracy: 0.70621 | val_auc: 0.72954 | val_balanced_accuracy: 0.64084 |  0:01:10s\n",
      "epoch 55 | loss: 0.42223 | train_auc: 0.83563 | train_balanced_accuracy: 0.63741 | val_auc: 0.74965 | val_balanced_accuracy: 0.59761 |  0:01:11s\n",
      "epoch 56 | loss: 0.42667 | train_auc: 0.8127  | train_balanced_accuracy: 0.70154 | val_auc: 0.72006 | val_balanced_accuracy: 0.6552  |  0:01:13s\n",
      "epoch 57 | loss: 0.42461 | train_auc: 0.81487 | train_balanced_accuracy: 0.63463 | val_auc: 0.73914 | val_balanced_accuracy: 0.59011 |  0:01:14s\n",
      "epoch 58 | loss: 0.42362 | train_auc: 0.79742 | train_balanced_accuracy: 0.70101 | val_auc: 0.69731 | val_balanced_accuracy: 0.63462 |  0:01:15s\n",
      "epoch 59 | loss: 0.41688 | train_auc: 0.81928 | train_balanced_accuracy: 0.64905 | val_auc: 0.73529 | val_balanced_accuracy: 0.60205 |  0:01:17s\n",
      "epoch 60 | loss: 0.41057 | train_auc: 0.83029 | train_balanced_accuracy: 0.66993 | val_auc: 0.75245 | val_balanced_accuracy: 0.61725 |  0:01:18s\n",
      "epoch 61 | loss: 0.40544 | train_auc: 0.83699 | train_balanced_accuracy: 0.64375 | val_auc: 0.7638  | val_balanced_accuracy: 0.59076 |  0:01:19s\n",
      "epoch 62 | loss: 0.40682 | train_auc: 0.83123 | train_balanced_accuracy: 0.65496 | val_auc: 0.73822 | val_balanced_accuracy: 0.60608 |  0:01:21s\n",
      "epoch 63 | loss: 0.40142 | train_auc: 0.82913 | train_balanced_accuracy: 0.67927 | val_auc: 0.74701 | val_balanced_accuracy: 0.62141 |  0:01:22s\n",
      "epoch 64 | loss: 0.39446 | train_auc: 0.82319 | train_balanced_accuracy: 0.68288 | val_auc: 0.7215  | val_balanced_accuracy: 0.61771 |  0:01:23s\n",
      "epoch 65 | loss: 0.4024  | train_auc: 0.83028 | train_balanced_accuracy: 0.67803 | val_auc: 0.73879 | val_balanced_accuracy: 0.61903 |  0:01:25s\n",
      "epoch 66 | loss: 0.39179 | train_auc: 0.83476 | train_balanced_accuracy: 0.68858 | val_auc: 0.7402  | val_balanced_accuracy: 0.61607 |  0:01:26s\n",
      "epoch 67 | loss: 0.38875 | train_auc: 0.84026 | train_balanced_accuracy: 0.68246 | val_auc: 0.73926 | val_balanced_accuracy: 0.61273 |  0:01:27s\n",
      "epoch 68 | loss: 0.38734 | train_auc: 0.83871 | train_balanced_accuracy: 0.70911 | val_auc: 0.71828 | val_balanced_accuracy: 0.63257 |  0:01:29s\n",
      "epoch 69 | loss: 0.38489 | train_auc: 0.82947 | train_balanced_accuracy: 0.69822 | val_auc: 0.73461 | val_balanced_accuracy: 0.62638 |  0:01:30s\n",
      "epoch 70 | loss: 0.38898 | train_auc: 0.84107 | train_balanced_accuracy: 0.68868 | val_auc: 0.72166 | val_balanced_accuracy: 0.61193 |  0:01:31s\n",
      "epoch 71 | loss: 0.38607 | train_auc: 0.83981 | train_balanced_accuracy: 0.70917 | val_auc: 0.74188 | val_balanced_accuracy: 0.63526 |  0:01:33s\n",
      "epoch 72 | loss: 0.39469 | train_auc: 0.85196 | train_balanced_accuracy: 0.68386 | val_auc: 0.75387 | val_balanced_accuracy: 0.61162 |  0:01:34s\n",
      "epoch 73 | loss: 0.37872 | train_auc: 0.85343 | train_balanced_accuracy: 0.68159 | val_auc: 0.74994 | val_balanced_accuracy: 0.61248 |  0:01:35s\n",
      "epoch 74 | loss: 0.37725 | train_auc: 0.83411 | train_balanced_accuracy: 0.69423 | val_auc: 0.73802 | val_balanced_accuracy: 0.6254  |  0:01:37s\n",
      "epoch 75 | loss: 0.37487 | train_auc: 0.82868 | train_balanced_accuracy: 0.69635 | val_auc: 0.71837 | val_balanced_accuracy: 0.63303 |  0:01:38s\n",
      "epoch 76 | loss: 0.37169 | train_auc: 0.8406  | train_balanced_accuracy: 0.71842 | val_auc: 0.73164 | val_balanced_accuracy: 0.64929 |  0:01:40s\n",
      "epoch 77 | loss: 0.36358 | train_auc: 0.85366 | train_balanced_accuracy: 0.73015 | val_auc: 0.7344  | val_balanced_accuracy: 0.64535 |  0:01:41s\n",
      "epoch 78 | loss: 0.36673 | train_auc: 0.85515 | train_balanced_accuracy: 0.75283 | val_auc: 0.70263 | val_balanced_accuracy: 0.64564 |  0:01:43s\n",
      "epoch 79 | loss: 0.36122 | train_auc: 0.67636 | train_balanced_accuracy: 0.63797 | val_auc: 0.62048 | val_balanced_accuracy: 0.57704 |  0:01:44s\n",
      "epoch 80 | loss: 0.36013 | train_auc: 0.84348 | train_balanced_accuracy: 0.7125  | val_auc: 0.72968 | val_balanced_accuracy: 0.62738 |  0:01:45s\n",
      "epoch 81 | loss: 0.3657  | train_auc: 0.86571 | train_balanced_accuracy: 0.68247 | val_auc: 0.75318 | val_balanced_accuracy: 0.61338 |  0:01:47s\n",
      "epoch 82 | loss: 0.35336 | train_auc: 0.8541  | train_balanced_accuracy: 0.72345 | val_auc: 0.73161 | val_balanced_accuracy: 0.63311 |  0:01:48s\n",
      "epoch 83 | loss: 0.35831 | train_auc: 0.89728 | train_balanced_accuracy: 0.69587 | val_auc: 0.75215 | val_balanced_accuracy: 0.59785 |  0:01:49s\n",
      "epoch 84 | loss: 0.3633  | train_auc: 0.87539 | train_balanced_accuracy: 0.70792 | val_auc: 0.745   | val_balanced_accuracy: 0.62025 |  0:01:51s\n",
      "epoch 85 | loss: 0.36043 | train_auc: 0.70342 | train_balanced_accuracy: 0.6488  | val_auc: 0.64104 | val_balanced_accuracy: 0.598   |  0:01:52s\n",
      "epoch 86 | loss: 0.35223 | train_auc: 0.83775 | train_balanced_accuracy: 0.70827 | val_auc: 0.68395 | val_balanced_accuracy: 0.60943 |  0:01:54s\n",
      "epoch 87 | loss: 0.35729 | train_auc: 0.84553 | train_balanced_accuracy: 0.71431 | val_auc: 0.71622 | val_balanced_accuracy: 0.63584 |  0:01:55s\n",
      "epoch 88 | loss: 0.3479  | train_auc: 0.87649 | train_balanced_accuracy: 0.71191 | val_auc: 0.73446 | val_balanced_accuracy: 0.61716 |  0:01:56s\n",
      "epoch 89 | loss: 0.34628 | train_auc: 0.87379 | train_balanced_accuracy: 0.72535 | val_auc: 0.7489  | val_balanced_accuracy: 0.63604 |  0:01:58s\n",
      "epoch 90 | loss: 0.34631 | train_auc: 0.84392 | train_balanced_accuracy: 0.71269 | val_auc: 0.71322 | val_balanced_accuracy: 0.62377 |  0:01:59s\n",
      "epoch 91 | loss: 0.35285 | train_auc: 0.86396 | train_balanced_accuracy: 0.76119 | val_auc: 0.72667 | val_balanced_accuracy: 0.66098 |  0:02:01s\n",
      "epoch 92 | loss: 0.35753 | train_auc: 0.87403 | train_balanced_accuracy: 0.78521 | val_auc: 0.73621 | val_balanced_accuracy: 0.67442 |  0:02:02s\n",
      "epoch 93 | loss: 0.34631 | train_auc: 0.83708 | train_balanced_accuracy: 0.71822 | val_auc: 0.69535 | val_balanced_accuracy: 0.62543 |  0:02:04s\n",
      "epoch 94 | loss: 0.34474 | train_auc: 0.70341 | train_balanced_accuracy: 0.66086 | val_auc: 0.62789 | val_balanced_accuracy: 0.59306 |  0:02:05s\n",
      "epoch 95 | loss: 0.33225 | train_auc: 0.88767 | train_balanced_accuracy: 0.71963 | val_auc: 0.74705 | val_balanced_accuracy: 0.62331 |  0:02:06s\n",
      "epoch 96 | loss: 0.33207 | train_auc: 0.86994 | train_balanced_accuracy: 0.70659 | val_auc: 0.74163 | val_balanced_accuracy: 0.62672 |  0:02:08s\n",
      "epoch 97 | loss: 0.33027 | train_auc: 0.72274 | train_balanced_accuracy: 0.67283 | val_auc: 0.65208 | val_balanced_accuracy: 0.61086 |  0:02:09s\n",
      "epoch 98 | loss: 0.33114 | train_auc: 0.88401 | train_balanced_accuracy: 0.75595 | val_auc: 0.71133 | val_balanced_accuracy: 0.6337  |  0:02:11s\n",
      "epoch 99 | loss: 0.32642 | train_auc: 0.88496 | train_balanced_accuracy: 0.79338 | val_auc: 0.71629 | val_balanced_accuracy: 0.66114 |  0:02:12s\n",
      "epoch 100| loss: 0.3201  | train_auc: 0.88115 | train_balanced_accuracy: 0.74824 | val_auc: 0.71744 | val_balanced_accuracy: 0.63365 |  0:02:13s\n",
      "epoch 101| loss: 0.31213 | train_auc: 0.87281 | train_balanced_accuracy: 0.73652 | val_auc: 0.71871 | val_balanced_accuracy: 0.62895 |  0:02:15s\n",
      "epoch 102| loss: 0.31745 | train_auc: 0.86673 | train_balanced_accuracy: 0.746   | val_auc: 0.69865 | val_balanced_accuracy: 0.6243  |  0:02:16s\n",
      "epoch 103| loss: 0.31595 | train_auc: 0.88637 | train_balanced_accuracy: 0.79417 | val_auc: 0.71739 | val_balanced_accuracy: 0.66456 |  0:02:18s\n",
      "epoch 104| loss: 0.31999 | train_auc: 0.85399 | train_balanced_accuracy: 0.71936 | val_auc: 0.69111 | val_balanced_accuracy: 0.60623 |  0:02:19s\n",
      "epoch 105| loss: 0.31157 | train_auc: 0.8628  | train_balanced_accuracy: 0.75812 | val_auc: 0.69451 | val_balanced_accuracy: 0.62824 |  0:02:21s\n",
      "epoch 106| loss: 0.30793 | train_auc: 0.88589 | train_balanced_accuracy: 0.77143 | val_auc: 0.72722 | val_balanced_accuracy: 0.64903 |  0:02:22s\n",
      "epoch 107| loss: 0.30823 | train_auc: 0.69232 | train_balanced_accuracy: 0.66844 | val_auc: 0.61063 | val_balanced_accuracy: 0.58366 |  0:02:23s\n",
      "epoch 108| loss: 0.31576 | train_auc: 0.9001  | train_balanced_accuracy: 0.77423 | val_auc: 0.73231 | val_balanced_accuracy: 0.64195 |  0:02:25s\n",
      "epoch 109| loss: 0.31483 | train_auc: 0.85118 | train_balanced_accuracy: 0.74397 | val_auc: 0.69983 | val_balanced_accuracy: 0.63032 |  0:02:26s\n",
      "epoch 110| loss: 0.30542 | train_auc: 0.894   | train_balanced_accuracy: 0.80809 | val_auc: 0.71939 | val_balanced_accuracy: 0.65804 |  0:02:28s\n",
      "epoch 111| loss: 0.30097 | train_auc: 0.87474 | train_balanced_accuracy: 0.78863 | val_auc: 0.69819 | val_balanced_accuracy: 0.64541 |  0:02:29s\n",
      "epoch 112| loss: 0.29336 | train_auc: 0.89714 | train_balanced_accuracy: 0.75322 | val_auc: 0.72634 | val_balanced_accuracy: 0.62577 |  0:02:31s\n",
      "epoch 113| loss: 0.2928  | train_auc: 0.88876 | train_balanced_accuracy: 0.76661 | val_auc: 0.71589 | val_balanced_accuracy: 0.63844 |  0:02:32s\n",
      "epoch 114| loss: 0.28897 | train_auc: 0.89237 | train_balanced_accuracy: 0.77824 | val_auc: 0.70865 | val_balanced_accuracy: 0.63728 |  0:02:34s\n",
      "epoch 115| loss: 0.28911 | train_auc: 0.89411 | train_balanced_accuracy: 0.75681 | val_auc: 0.71166 | val_balanced_accuracy: 0.62867 |  0:02:35s\n",
      "epoch 116| loss: 0.28677 | train_auc: 0.88549 | train_balanced_accuracy: 0.75371 | val_auc: 0.70998 | val_balanced_accuracy: 0.62856 |  0:02:36s\n",
      "epoch 117| loss: 0.29659 | train_auc: 0.8887  | train_balanced_accuracy: 0.79969 | val_auc: 0.6903  | val_balanced_accuracy: 0.63975 |  0:02:38s\n",
      "epoch 118| loss: 0.30669 | train_auc: 0.91354 | train_balanced_accuracy: 0.77401 | val_auc: 0.73206 | val_balanced_accuracy: 0.64564 |  0:02:39s\n",
      "epoch 119| loss: 0.30121 | train_auc: 0.90092 | train_balanced_accuracy: 0.78282 | val_auc: 0.71195 | val_balanced_accuracy: 0.63603 |  0:02:41s\n",
      "epoch 120| loss: 0.30192 | train_auc: 0.69663 | train_balanced_accuracy: 0.67519 | val_auc: 0.6094  | val_balanced_accuracy: 0.58032 |  0:02:42s\n",
      "epoch 121| loss: 0.28925 | train_auc: 0.87934 | train_balanced_accuracy: 0.79891 | val_auc: 0.69201 | val_balanced_accuracy: 0.6441  |  0:02:43s\n",
      "epoch 122| loss: 0.28771 | train_auc: 0.87397 | train_balanced_accuracy: 0.74811 | val_auc: 0.68665 | val_balanced_accuracy: 0.62088 |  0:02:45s\n",
      "epoch 123| loss: 0.28785 | train_auc: 0.90757 | train_balanced_accuracy: 0.79228 | val_auc: 0.71448 | val_balanced_accuracy: 0.6392  |  0:02:46s\n",
      "epoch 124| loss: 0.28579 | train_auc: 0.89883 | train_balanced_accuracy: 0.77144 | val_auc: 0.70491 | val_balanced_accuracy: 0.6322  |  0:02:48s\n",
      "epoch 125| loss: 0.27957 | train_auc: 0.89199 | train_balanced_accuracy: 0.77832 | val_auc: 0.68967 | val_balanced_accuracy: 0.61497 |  0:02:49s\n",
      "epoch 126| loss: 0.28011 | train_auc: 0.88443 | train_balanced_accuracy: 0.75932 | val_auc: 0.67881 | val_balanced_accuracy: 0.61434 |  0:02:51s\n",
      "epoch 127| loss: 0.28125 | train_auc: 0.9001  | train_balanced_accuracy: 0.78078 | val_auc: 0.69445 | val_balanced_accuracy: 0.62475 |  0:02:52s\n",
      "epoch 128| loss: 0.27966 | train_auc: 0.90747 | train_balanced_accuracy: 0.81997 | val_auc: 0.70154 | val_balanced_accuracy: 0.64082 |  0:02:53s\n",
      "epoch 129| loss: 0.27519 | train_auc: 0.89811 | train_balanced_accuracy: 0.77371 | val_auc: 0.70749 | val_balanced_accuracy: 0.62767 |  0:02:55s\n",
      "epoch 130| loss: 0.28506 | train_auc: 0.9129  | train_balanced_accuracy: 0.76598 | val_auc: 0.70738 | val_balanced_accuracy: 0.62608 |  0:02:56s\n",
      "epoch 131| loss: 0.27373 | train_auc: 0.91394 | train_balanced_accuracy: 0.77762 | val_auc: 0.70576 | val_balanced_accuracy: 0.6291  |  0:02:58s\n",
      "epoch 132| loss: 0.25727 | train_auc: 0.91842 | train_balanced_accuracy: 0.77108 | val_auc: 0.7063  | val_balanced_accuracy: 0.62282 |  0:02:59s\n",
      "epoch 133| loss: 0.24944 | train_auc: 0.92235 | train_balanced_accuracy: 0.76301 | val_auc: 0.72294 | val_balanced_accuracy: 0.6279  |  0:03:01s\n",
      "epoch 134| loss: 0.25935 | train_auc: 0.9314  | train_balanced_accuracy: 0.79503 | val_auc: 0.7123  | val_balanced_accuracy: 0.61886 |  0:03:02s\n",
      "epoch 135| loss: 0.25856 | train_auc: 0.71015 | train_balanced_accuracy: 0.67555 | val_auc: 0.61899 | val_balanced_accuracy: 0.58344 |  0:03:04s\n",
      "epoch 136| loss: 0.25713 | train_auc: 0.91246 | train_balanced_accuracy: 0.79587 | val_auc: 0.70049 | val_balanced_accuracy: 0.6254  |  0:03:05s\n",
      "epoch 137| loss: 0.24889 | train_auc: 0.91958 | train_balanced_accuracy: 0.80442 | val_auc: 0.71909 | val_balanced_accuracy: 0.64534 |  0:03:07s\n",
      "epoch 138| loss: 0.25229 | train_auc: 0.90774 | train_balanced_accuracy: 0.77914 | val_auc: 0.69589 | val_balanced_accuracy: 0.62104 |  0:03:08s\n",
      "epoch 139| loss: 0.26429 | train_auc: 0.93511 | train_balanced_accuracy: 0.85282 | val_auc: 0.71454 | val_balanced_accuracy: 0.66071 |  0:03:09s\n",
      "epoch 140| loss: 0.24878 | train_auc: 0.68387 | train_balanced_accuracy: 0.65882 | val_auc: 0.60278 | val_balanced_accuracy: 0.57307 |  0:03:11s\n",
      "epoch 141| loss: 0.25863 | train_auc: 0.76819 | train_balanced_accuracy: 0.7052  | val_auc: 0.64425 | val_balanced_accuracy: 0.59351 |  0:03:12s\n",
      "epoch 142| loss: 0.26339 | train_auc: 0.94925 | train_balanced_accuracy: 0.87429 | val_auc: 0.73854 | val_balanced_accuracy: 0.66638 |  0:03:14s\n",
      "epoch 143| loss: 0.26338 | train_auc: 0.73608 | train_balanced_accuracy: 0.67898 | val_auc: 0.62952 | val_balanced_accuracy: 0.59044 |  0:03:15s\n",
      "epoch 144| loss: 0.25364 | train_auc: 0.93226 | train_balanced_accuracy: 0.78057 | val_auc: 0.72572 | val_balanced_accuracy: 0.62702 |  0:03:17s\n",
      "epoch 145| loss: 0.24878 | train_auc: 0.91007 | train_balanced_accuracy: 0.79726 | val_auc: 0.70342 | val_balanced_accuracy: 0.63334 |  0:03:18s\n",
      "epoch 146| loss: 0.25189 | train_auc: 0.70184 | train_balanced_accuracy: 0.67132 | val_auc: 0.61    | val_balanced_accuracy: 0.5785  |  0:03:20s\n",
      "epoch 147| loss: 0.245   | train_auc: 0.9193  | train_balanced_accuracy: 0.79383 | val_auc: 0.7009  | val_balanced_accuracy: 0.62681 |  0:03:21s\n",
      "epoch 148| loss: 0.268   | train_auc: 0.91055 | train_balanced_accuracy: 0.79202 | val_auc: 0.70517 | val_balanced_accuracy: 0.63715 |  0:03:22s\n",
      "epoch 149| loss: 0.25487 | train_auc: 0.92701 | train_balanced_accuracy: 0.82341 | val_auc: 0.69383 | val_balanced_accuracy: 0.63127 |  0:03:24s\n",
      "epoch 150| loss: 0.25414 | train_auc: 0.91477 | train_balanced_accuracy: 0.78902 | val_auc: 0.70129 | val_balanced_accuracy: 0.62918 |  0:03:25s\n",
      "epoch 151| loss: 0.24549 | train_auc: 0.93138 | train_balanced_accuracy: 0.83826 | val_auc: 0.70542 | val_balanced_accuracy: 0.65243 |  0:03:27s\n",
      "epoch 152| loss: 0.25104 | train_auc: 0.9031  | train_balanced_accuracy: 0.80205 | val_auc: 0.68153 | val_balanced_accuracy: 0.63425 |  0:03:28s\n",
      "\n",
      "Early stopping occurred at epoch 152 with best_epoch = 92 and best_val_balanced_accuracy = 0.67442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "clf.fit(\n",
    "    X_train_np, y_train,\n",
    "    eval_set=[(X_train_np, y_train), (X_val_np, y_val)],\n",
    "    eval_name=['train', 'val'],\n",
    "    eval_metric=['auc', 'balanced_accuracy'],\n",
    "    max_epochs=300, patience=60,\n",
    "    batch_size=2048, virtual_batch_size=1024,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee60d4a-4ab4-417a-9650-2f46055a9ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.50      0.48      1267\n",
      "           1       0.81      0.78      0.79      3401\n",
      "\n",
      "    accuracy                           0.70      4668\n",
      "   macro avg       0.63      0.64      0.64      4668\n",
      "weighted avg       0.71      0.70      0.71      4668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_np)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e4f22-d7af-4e20-b00c-41a6312e2f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at eu_tabnet_1118.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:454: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_state_dict = torch.load(f, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.50      0.48      1267\n",
      "           1       0.81      0.78      0.79      3401\n",
      "\n",
      "    accuracy                           0.70      4668\n",
      "   macro avg       0.63      0.64      0.64      4668\n",
      "weighted avg       0.71      0.70      0.71      4668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "clf.save_model('eu_tabnet_1118')\n",
    "# Later, load the model without retraining\n",
    "clf_loaded = TabNetClassifier()\n",
    "clf_loaded.load_model('eu_tabnet_1118.zip')\n",
    "# Verify the loaded model\n",
    "y_pred_loaded = clf_loaded.predict(X_test_np)\n",
    "print(classification_report(y_test, y_pred_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5406a5b-5c6c-4954-9164-075bea0d11d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_true = y_test\n",
    "y_pred_proba = y_pred \n",
    "# Compute ROC curve and ROC area\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotting the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Chance line')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"results/241118 EU/TabNet_roc_curve.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281cac4-f380-4bac-9402-7326a62785b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig(\"results/241118 EU/TabNet_confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
